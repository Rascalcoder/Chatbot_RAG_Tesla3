# ==========================================
# RAG AI ASSZISZTENS - KÖRNYEZETI VÁLTOZÓK
# HIBRID KONFIGURÁCIÓ (8 GB RAM rendszerekhez)
# ==========================================

# OpenAI API kulcs (KÖTELEZŐ a HIBRID konfighoz)
# Szerezd be itt: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# EMBEDDING MODELL (lokális, kis RAM igény ~90 MB)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# LLM MODELL (felhő, nincs RAM igény)
LLM_MODEL=gpt-3.5-turbo

# VEKTOR ADATBÁZIS
# ChromaDB adatbázis elérési útja
VECTOR_DB_PATH=./data/vector_db

# CHUNKING PARAMÉTEREK
# Dokumentumok felosztásának mérete (karakterek száma)
CHUNK_SIZE=1000

# Chunk-ok közötti átfedés (karakterek száma)
# Segít abban, hogy az információ ne szakadjon középen
CHUNK_OVERLAP=200

# RETRIEVAL PARAMÉTEREK
# Hány darab relevánsan lekérdezett dokumentum visszaadásához
TOP_K=5

# Hasonlósági küszöb (0.0-1.0) - alacsony relevancia szűrésére
# 0.0 = minden eredmény átmegy, 0.3 = ajánlott, 0.5 = szigorú
SIMILARITY_THRESHOLD=0.3

# ==========================================
# MEGJEGYZÉSEK
# ==========================================
#
# 1. Az alapértelmezett konfiguráció HELYI MODELLEKET használ:
#    - BGE-M3 embedding (1024-dimenziós vektorok)
#    - Qwen 4B LLM (instrukciókövetésre képes)
#    Az első futtatáskor ~10 GB-ot fog letölteni.
#
# 2. OpenAI használatához:
#    - Kell a OPENAI_API_KEY
#    - EMBEDDING_MODEL="text-embedding-ada-002"
#    - LLM_MODEL="gpt-4" vagy "gpt-3.5-turbo"
#
# 3. Pythonba betöltéshez:
#    - A projekt automatikusan betölti ezt a .env fájlt
#    - Vagy: python -m dotenv load
#
# 4. Módosítás után újra kell indítani az alkalmazást:
#    - streamlit run app.py
#
