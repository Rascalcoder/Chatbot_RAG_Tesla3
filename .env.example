# ==========================================
# RAG AI ASSZISZTENS - KÖRNYEZETI VÁLTOZÓK
# ==========================================

# OPCIONÁLIS: OpenAI API kulcs
# Csak akkor szükséges, ha OpenAI API-t szeretnél használni
# Az alapértelmezett helyi modellek (BGE-M3, Qwen-4B) ezt nem igénylik
# OPENAI_API_KEY=your_openai_api_key_here

# EMBEDDING MODELL
# Alapértelmezett: BAAI/bge-m3 (helyi modell)
# Alternatívák: "text-embedding-ada-002" (OpenAI), bge-large, etc.
EMBEDDING_MODEL=BAAI/bge-m3

# LLM MODELL
# Alapértelmezett: Qwen/Qwen3-4B-Instruct-2507 (helyi modell)
# Alternatívák: "gpt-4", "gpt-3.5-turbo" (OpenAI), meta-llama/Llama-2-7b, etc.
LLM_MODEL=Qwen/Qwen3-4B-Instruct-2507

# VEKTOR ADATBÁZIS
# ChromaDB adatbázis elérési útja
VECTOR_DB_PATH=./data/vector_db

# CHUNKING PARAMÉTEREK
# Dokumentumok felosztásának mérete (karakterek száma)
CHUNK_SIZE=1000

# Chunk-ok közötti átfedés (karakterek száma)
# Segít abban, hogy az információ ne szakadjon középen
CHUNK_OVERLAP=200

# RETRIEVAL PARAMÉTEREK
# Hány darab relevánsan lekérdezett dokumentum visszaadásához
TOP_K=5

# Hasonlósági küszöb (0.0-1.0) - alacsony relevancia szűrésére
# 0.0 = minden eredmény átmegy, 0.3 = ajánlott, 0.5 = szigorú
SIMILARITY_THRESHOLD=0.3

# ==========================================
# MEGJEGYZÉSEK
# ==========================================
#
# 1. Az alapértelmezett konfiguráció HELYI MODELLEKET használ:
#    - BGE-M3 embedding (1024-dimenziós vektorok)
#    - Qwen 4B LLM (instrukciókövetésre képes)
#    Az első futtatáskor ~10 GB-ot fog letölteni.
#
# 2. OpenAI használatához:
#    - Kell a OPENAI_API_KEY
#    - EMBEDDING_MODEL="text-embedding-ada-002"
#    - LLM_MODEL="gpt-4" vagy "gpt-3.5-turbo"
#
# 3. Pythonba betöltéshez:
#    - A projekt automatikusan betölti ezt a .env fájlt
#    - Vagy: python -m dotenv load
#
# 4. Módosítás után újra kell indítani az alkalmazást:
#    - streamlit run app.py
#
