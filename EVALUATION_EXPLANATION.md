# Mi√©rt j√∂nnek ki mindig ugyanazok az eredm√©nyek?

## R√∂vid v√°lasz

Az evaluation **t√©nyleg √∫jrafut** minden alkalommal, de az eredm√©nyek **determinisztikusak**, mert:

1. **Statikus tesztesetek**: A `PROMPT_TEST_CASES` mindig ugyanazokat a query-ket tartalmazza
2. **Determinisztikus LLM**: Az LLM `temperature=0`-val fut, ami mindig ugyanazt a v√°laszt adja ugyanarra a query-re
3. **Ugyanaz a dokumentum**: A vector DB tartalma nem v√°ltozik

Ez **nem bug, hanem sz√°nd√©kos design**! Az evaluation c√©lja a **reproduk√°lhat√≥s√°g** √©s **√∂sszehasonl√≠that√≥s√°g**.

---

## R√©szletes magyar√°zat

### 1. Statikus tesztesetek

```python
PROMPT_TEST_CASES = [
    {
        'query': 'Hol kapcsolom be a Walk Away Lock-ot?',
        'context': [...],  # Mindig ugyanaz
        'expected_contains': ['Controls', 'Locks', 'Walk Away Lock']
    },
    # ... tov√°bbi tesztesetek
]
```

**K√∂vetkezm√©ny**: Minden futtat√°skor ugyanazokat a query-ket tesztelj√ºk.

### 2. Determinisztikus LLM (temperature=0)

**F√°jl**: `src/evaluation/prompt_eval.py`

```python
response = self._judge_client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[...],
    temperature=0  # ‚Üê Determinisztikus!
)
```

**K√∂vetkezm√©ny**: 
- Ugyanaz a query + ugyanaz a context = **mindig ugyanaz a v√°lasz**
- Ez **sz√°nd√©kos**, mert az evaluation **reproduk√°lhat√≥** kell legyen

### 3. Ugyanaz a dokumentum

A vector DB tartalma nem v√°ltozik futtat√°sok k√∂z√∂tt, ez√©rt:
- Ugyanaz a query ‚Üí ugyanazok a retrieved chunk-ok
- Ugyanazok a chunk-ok ‚Üí ugyanaz a context
- Ugyanaz a context ‚Üí ugyanaz a v√°lasz

---

## Mikor v√°ltoznak az eredm√©nyek?

Az eredm√©nyek **csak akkor** v√°ltoznak, ha:

1. **√öj dokumentumot t√∂ltesz fel**: M√°s chunk-ok ‚Üí m√°s context ‚Üí m√°s v√°laszok
2. **M√≥dos√≠tod a teszteseteket**: M√°s query-k ‚Üí m√°s v√°laszok
3. **M√≥dos√≠tod a system promptot**: M√°s instrukci√≥k ‚Üí m√°s v√°laszok
4. **M√≥dos√≠tod a chunking strat√©gi√°t**: M√°s chunk-ok ‚Üí m√°s context ‚Üí m√°s v√°laszok
5. **M√≥dos√≠tod a retrieval/reranking be√°ll√≠t√°sokat**: M√°s chunk-ok ker√ºlnek el≈ë ‚Üí m√°s context

---

## Hogyan ellen≈ërizheted, hogy t√©nyleg √∫jrafut?

### M√≥dszer 1: Id≈ëb√©lyeg

Az UI most m√°r mutatja az utols√≥ futtat√°s id≈ëpontj√°t:

```
‚è±Ô∏è Utols√≥ futtat√°s: 2026-02-10 15:30:45 (12.3s)
```

Minden gombnyom√°skor ez az id≈ëb√©lyeg friss√ºl, ami bizony√≠tja, hogy √∫jrafut.

### M√≥dszer 2: Cache t√∂rl√©se

Haszn√°ld a "üóëÔ∏è Cache T√∂rl√©se" gombot:
1. T√∂r√∂ld a cache-t
2. Futtasd √∫jra az evaluationt
3. Az eredm√©nyek **ugyanazok** lesznek (mert determinisztikus)

### M√≥dszer 3: M√≥dos√≠tsd a teszteseteket

Ha m√°s query-t adsz meg, m√°s eredm√©nyeket kapsz:

```python
# src/evaluation/test_cases.py
PROMPT_TEST_CASES = [
    {
        'query': '√öj k√©rd√©s, amit m√©g nem teszteltem',  # ‚Üê √öj query
        'context': [...],
        'expected_contains': [...]
    }
]
```

---

## Mi√©rt j√≥ ez √≠gy?

### ‚úÖ Reproduk√°lhat√≥s√°g
- Ugyanazok az eredm√©nyek ‚Üí k√∂nny≈± √∂sszehasonl√≠tani verzi√≥kat
- "A m√∫lt h√©ten 0.97 volt a context relevance, most is 0.97" ‚Üí **nincs regresszi√≥**

### ‚úÖ Konzisztencia
- Determinisztikus LLM ‚Üí nincs random fluktu√°ci√≥
- K√∂nnyebb debugolni, ha mindig ugyanaz az eredm√©ny

### ‚úÖ K√∂lts√©ghat√©konys√°g
- Nem kell minden alkalommal √∫jra gener√°lni a v√°laszokat
- Session state cache ‚Üí gyors UI friss√≠t√©s

---

## Mit tehetsz, ha v√°ltozatoss√°got akarsz?

### Opci√≥ 1: N√∂veld a temperature-t

**F√°jl**: `src/evaluation/prompt_eval.py`

```python
response = self._judge_client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[...],
    temperature=0.7  # ‚Üê V√°ltozatosabb v√°laszok
)
```

**H√°tr√°ny**: Az eredm√©nyek nem lesznek reproduk√°lhat√≥ak.

### Opci√≥ 2: Adj hozz√° √∫j teszteseteket

**F√°jl**: `src/evaluation/test_cases.py`

Adj hozz√° √∫j query-ket, √©s az evaluation √∫j eredm√©nyeket fog adni ezekre.

### Opci√≥ 3: V√°ltoztasd meg a dokumentumot

T√∂lts fel egy m√°sik PDF-et, √©s az evaluation m√°s chunk-okkal fog dolgozni.

---

## √ñsszefoglal√°s

| K√©rd√©s | V√°lasz |
|--------|--------|
| **√öjrafut-e az evaluation?** | ‚úÖ Igen, minden gombnyom√°skor |
| **Mi√©rt ugyanazok az eredm√©nyek?** | Determinisztikus LLM (temperature=0) + statikus tesztesetek |
| **Ez bug?** | ‚ùå Nem, ez sz√°nd√©kos (reproduk√°lhat√≥s√°g) |
| **Hogyan ellen≈ërz√∂m?** | Id≈ëb√©lyeg az UI-ban |
| **Hogyan v√°ltoztatom meg?** | √öj tesztesetek / √∫j dokumentum / temperature n√∂vel√©se |

**Konkl√∫zi√≥**: Az evaluation **helyesen m≈±k√∂dik**. Az eredm√©nyek az√©rt ugyanazok, mert az evaluation **reproduk√°lhat√≥** √©s **determinisztikus**, ami egy **j√≥ dolog** production k√∂rnyezetben! üéØ


