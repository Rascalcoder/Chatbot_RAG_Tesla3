# RAG AlapÃº AI Asszisztens

Ez a projekt egy teljes kÃ¶rÅ± RAG (Retrieval-Augmented Generation) alapÃº AI asszisztens implementÃ¡ciÃ³ja, amely kÃ©pes dokumentumok feldolgozÃ¡sÃ¡ra, relevÃ¡ns informÃ¡ciÃ³k visszakeresÃ©sÃ©re Ã©s intelligens vÃ¡laszok generÃ¡lÃ¡sÃ¡ra.

## ğŸš€ FunkciÃ³k

### RAG Rendszer ArchitektÃºra
- âœ… Dokumentum feldolgozÃ¡s Ã©s chunking stratÃ©gia
- âœ… Embedding modell integrÃ¡ciÃ³ (OpenAI, lokÃ¡lis alternatÃ­vÃ¡k)
- âœ… Vektor adatbÃ¡zis (ChromaDB)
- âœ… Retrieval Ã©s reranking mechanizmus
- âœ… LLM integrÃ¡ciÃ³ vÃ¡laszgenerÃ¡lÃ¡shoz (streaming tÃ¡mogatÃ¡ssal)

### AlkalmazÃ¡s FunkciÃ³k
- âœ… Webes felÃ¼let (Streamlit)
- âœ… Dokumentum feltÃ¶ltÃ©s Ã©s kezelÃ©s
- âœ… Streaming vÃ¡laszok tÃ¡mogatÃ¡sa
- âœ… Session/conversation management

### HÃ¡romszintÅ± Evaluation Framework
- âœ… **RAG szintÅ± Ã©rtÃ©kelÃ©s**: Retrieval minÅ‘sÃ©g (precision, recall, MRR), embedding modell teljesÃ­tmÃ©ny, chunking stratÃ©gia hatÃ©konysÃ¡ga
- âœ… **Prompt szintÅ± Ã©rtÃ©kelÃ©s**: Single-turn eval, context relevance, hallucinÃ¡ciÃ³ detektÃ¡lÃ¡s, LLM-as-Judge
- âœ… **AlkalmazÃ¡s szintÅ± Ã©rtÃ©kelÃ©s**: Teljes user journey tesztelÃ©s, response quality, latency Ã©s performance metrikÃ¡k

### Monitoring Ã©s Analitika
- âœ… Token hasznÃ¡lat Ã©s kÃ¶ltsÃ©g tracking
- âœ… Latency metrikÃ¡k (first token, total response time)

## ğŸ“‹ TelepÃ­tÃ©s

### ElÅ‘feltÃ©telek
- Python 3.9 vagy Ãºjabb
- pip vagy conda

### LÃ©pÃ©sek

1. **Repository klÃ³nozÃ¡sa**
```bash
git clone <repository-url>
cd "7.het_ZÃ¡rÃ³ projekt"
```

2. **VirtuÃ¡lis kÃ¶rnyezet lÃ©trehozÃ¡sa (ajÃ¡nlott)**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# vagy
venv\Scripts\activate  # Windows
```

3. **FÃ¼ggÅ‘sÃ©gek telepÃ­tÃ©se**
```bash
pip install -r requirements.txt
```

4. **KÃ¶rnyezeti vÃ¡ltozÃ³k beÃ¡llÃ­tÃ¡sa**
```bash
cp .env.example .env
# Szerkeszd a .env fÃ¡jlt Ã©s add hozzÃ¡ az API kulcsokat
```

5. **AlkalmazÃ¡s indÃ­tÃ¡sa**
```bash
streamlit run app.py
```

A bÃ¶ngÃ©szÅ‘ben automatikusan megnyÃ­lik a `http://localhost:8501` cÃ­men.

## ğŸ”§ KonfigurÃ¡ciÃ³

A projekt **HIBRID konfigurÃ¡ciÃ³t** hasznÃ¡l, amely optimalizÃ¡lt 8 GB RAM-os rendszerekhez:

### ğŸ¯ HasznÃ¡lt KonfigurÃ¡ciÃ³:
- **Embedding**: `sentence-transformers/all-MiniLM-L6-v2` (helyi, ~90 MB)
- **LLM**: `gpt-3.5-turbo` (OpenAI API, nincs RAM igÃ©ny)
- **RAM igÃ©ny**: ~1-2 GB âœ…
- **KÃ¶ltsÃ©g**: ~$0.0005-0.001 / vÃ¡lasz

### BeÃ¡llÃ­tÃ¡s

Hozz lÃ©tre egy `.env` fÃ¡jlt a projekt gyÃ¶kerÃ©ben:

```env
# OpenAI API kulcs (kÃ¶telezÅ‘)
OPENAI_API_KEY=your_openai_api_key_here

# Embedding modell (helyi, kis RAM igÃ©ny)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# LLM modell (felhÅ‘, nincs RAM igÃ©ny)
LLM_MODEL=gpt-3.5-turbo

# Vector DB Ã©s chunking
VECTOR_DB_PATH=./data/vector_db
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K=5
```

**Fontos**:
- Az OpenAI API kulcs megszerzÃ©sÃ©hez: https://platform.openai.com/api-keys
- A kis embedding modell (~90 MB) automatikusan letÃ¶ltÅ‘dik az elsÅ‘ hasznÃ¡latkor
- A rendszer automatikusan felismeri az OpenAI modelleket

> ğŸ’¡ **AlternatÃ­v konfigurÃ¡ciÃ³k**: Ha szeretnÃ©d hasznÃ¡lni a teljes lokÃ¡lis konfigurÃ¡ciÃ³t (BGE-M3 + Qwen3-4B), nÃ©zd meg a [MODEL_INFO.md](MODEL_INFO.md) dokumentumot.

## ğŸ“ Projekt StruktÃºra

```
.
â”œâ”€â”€ app.py                      # Streamlit fÅ‘alkalmazÃ¡s
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document_processor.py    # Dokumentum feldolgozÃ¡s
â”‚   â”‚   â”œâ”€â”€ chunking.py              # Chunking stratÃ©gia
â”‚   â”‚   â”œâ”€â”€ embeddings.py            # Embedding kezelÃ©s
â”‚   â”‚   â”œâ”€â”€ vector_store.py           # Vektor adatbÃ¡zis
â”‚   â”‚   â”œâ”€â”€ retrieval.py              # Retrieval mechanizmus
â”‚   â”‚   â””â”€â”€ reranking.py              # Reranking
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ generator.py              # LLM vÃ¡laszgenerÃ¡lÃ¡s
â”‚   â”‚   â””â”€â”€ streaming.py              # Streaming tÃ¡mogatÃ¡s
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag_eval.py                # RAG szintÅ± Ã©rtÃ©kelÃ©s
â”‚   â”‚   â”œâ”€â”€ prompt_eval.py             # Prompt szintÅ± Ã©rtÃ©kelÃ©s
â”‚   â”‚   â”œâ”€â”€ app_eval.py                # AlkalmazÃ¡s szintÅ± Ã©rtÃ©kelÃ©s
â”‚   â”‚   â””â”€â”€ test_cases.py              # Teszt esetek
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py                 # MetrikÃ¡k gyÅ±jtÃ©se
â”‚   â”‚   â””â”€â”€ analytics.py               # Analitika
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ session_manager.py         # Session kezelÃ©s
â”œâ”€â”€ data/
â”‚   â””â”€â”€ documents/                    # FeltÃ¶ltÃ¶tt dokumentumok
â”œâ”€â”€ evaluations/
â”‚   â”œâ”€â”€ rag_evaluation_results.json
â”‚   â”œâ”€â”€ prompt_evaluation_results.json
â”‚   â””â”€â”€ app_evaluation_results.json
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_rag.py
â”‚   â”œâ”€â”€ test_retrieval.py
â”‚   â””â”€â”€ test_evaluation.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ§ª Evaluation FuttatÃ¡sa

### RAG SzintÅ± Evaluation
```bash
python -m src.evaluation.rag_eval
```

### Prompt SzintÅ± Evaluation
```bash
python -m src.evaluation.prompt_eval
```

### AlkalmazÃ¡s SzintÅ± Evaluation
```bash
python -m src.evaluation.app_eval
```

## ğŸ“Š Monitoring Dashboard

A monitoring dashboard elÃ©rhetÅ‘ a Streamlit alkalmazÃ¡sban a "Monitoring" oldalon, ahol megtekinthetÅ‘k:
- Token hasznÃ¡lat statisztikÃ¡k
- Latency metrikÃ¡k
- KÃ¶ltsÃ©g tracking
- HasznÃ¡lati trendek

## ğŸ“ HasznÃ¡lat

### AlapvetÅ‘ HasznÃ¡lat

1. **Dokumentum feltÃ¶ltÃ©s**: A fÅ‘oldalon tÃ¶lts fel PDF, TXT vagy DOCX fÃ¡jlokat
2. **KÃ©rdÃ©sek feltevÃ©se**: A chat felÃ¼leten tegyÃ©l fel kÃ©rdÃ©seket a feltÃ¶ltÃ¶tt dokumentumokrÃ³l
3. **EredmÃ©nyek megtekintÃ©se**: A vÃ¡laszok streaming formÃ¡ban jelennek meg
4. **Evaluation futtatÃ¡sa**: Az Evaluation oldalon futtathatsz teszteket

### Tesla Model 3 KÃ©zikÃ¶nyv HasznÃ¡lata

Ha a `model_3.pdf` fÃ¡jl a projekt kÃ¶nyvtÃ¡rÃ¡ban van:

**OpciÃ³ 1: Streamlit app-ban**
1. IndÃ­tsd el az app-ot: `streamlit run app.py`
2. A sidebar-ban tÃ¶ltsd fel a `model_3.pdf` fÃ¡jlt
3. KÃ©rdezz a Model 3-rÃ³l!

**OpciÃ³ 2: Teszt script**
```bash
python test_model3_manual.py
```

Ez automatikusan betÃ¶lti a PDF-et Ã©s futtat teszt kÃ©rdÃ©seket, majd interaktÃ­v mÃ³dba lÃ©p.

**OpciÃ³ 3: ElÅ‘re betÃ¶ltÃ©s**
```bash
python load_model3_manual.py
```

Ez elÅ‘re betÃ¶lti a dokumentumot, Ã­gy a Streamlit app indÃ­tÃ¡sakor mÃ¡r elÃ©rhetÅ‘ lesz.


## ğŸ“„ Licenc

Ez a projekt egy zÃ¡rÃ³projekt rÃ©sze.

## ğŸ‘¥ SzerzÅ‘

Projekt kÃ©szÃ­tÅ‘: Alasztics PÃ¡l

---

Sikeres hasznÃ¡latot kÃ­vÃ¡nunk! ğŸš€

