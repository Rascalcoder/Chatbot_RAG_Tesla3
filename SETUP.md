# Telep√≠t√©si √ötmutat√≥

## Gyors Kezd√©s

### 1. F√ºgg≈ës√©gek Telep√≠t√©se

```bash
pip install -r requirements.txt
```

### 2. K√∂rnyezeti V√°ltoz√≥k Be√°ll√≠t√°sa

A projekt **HIBRID konfigur√°ci√≥t** t√°mogat. V√°lassz a g√©pednek megfelel≈ë be√°ll√≠t√°st:

#### üéØ Opci√≥ A: Hibrid (Aj√°nlott 8 GB RAM-hoz)
```env
# .env f√°jl
OPENAI_API_KEY=your_api_key_here

# Kis lok√°lis embedding (~90 MB)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Felh≈ë LLM (nincs RAM ig√©ny)
LLM_MODEL=gpt-3.5-turbo

VECTOR_DB_PATH=./data/vector_db
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K=5
```

#### üöÄ Opci√≥ B: Teljes Lok√°lis (16+ GB RAM)
```env
# .env f√°jl (vagy haszn√°ld a .env.example-t)
# Teljes lok√°lis modellek
EMBEDDING_MODEL=BAAI/bge-m3
LLM_MODEL=Qwen/Qwen3-4B-Instruct-2507

VECTOR_DB_PATH=./data/vector_db
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K=5
```

**Megjegyz√©s**:
- Hibrid konfign√°l csak az embedding modell t√∂lt≈ëdik le (~90 MB)
- Teljes lok√°lis konfign√°l ~10 GB modell t√∂lt≈ëdik le az els≈ë futtat√°skor
- A rendszer automatikusan felismeri az OpenAI modelleket (gpt-* prefix alapj√°n)

### 3. Alkalmaz√°s Ind√≠t√°sa

```bash
streamlit run app.py
```

A b√∂ng√©sz≈ëben automatikusan megny√≠lik a `http://localhost:8501` c√≠men.

## Evaluation Futtat√°sa

### RAG Szint≈± Evaluation

```bash
python run_evaluation.py --type rag
```

### Prompt Szint≈± Evaluation

```bash
python run_evaluation.py --type prompt
```

### Alkalmaz√°s Szint≈± Evaluation

```bash
python run_evaluation.py --type app
```

### √ñsszes Evaluation

```bash
python run_evaluation.py --type all
```

## Haszn√°lat

### √Åltal√°nos Haszn√°lat

1. **Dokumentum Felt√∂lt√©s**: 
   - A bal oldali sidebar-ban t√∂lts fel PDF, TXT vagy DOCX f√°jlokat
   - Kattints a "Dokumentumok Hozz√°ad√°sa" gombra

2. **K√©rd√©sek Feltev√©se**:
   - A chat mez≈ëben tegy√©l fel k√©rd√©seket a felt√∂lt√∂tt dokumentumokr√≥l
   - A v√°laszok streaming form√°ban jelennek meg

3. **Monitoring**:
   - A "Monitoring" oldalon tekintheted meg a haszn√°lati statisztik√°kat
   - Token haszn√°lat, k√∂lts√©g, latency metrik√°k

### Tesla Model 3 K√©zik√∂nyv

Ha a `model_3.pdf` f√°jl a projekt k√∂nyvt√°r√°ban van:

**Gyors tesztel√©s:**
```bash
python test_model3_manual.py
```

**El≈ëre bet√∂lt√©s (aj√°nlott):**
```bash
python load_model3_manual.py
streamlit run app.py
```

Ezut√°n a Streamlit app-ban m√°r el√©rhet≈ë lesz a Model 3 k√©zik√∂nyv, √©s k√∂zvetlen√ºl k√©rdezhetsz r√°!

## Hibaelh√°r√≠t√°s

### Hiba: "OPENAI_API_KEY nincs be√°ll√≠tva"

- Ellen≈ërizd, hogy a `.env` f√°jl l√©tezik √©s tartalmazza az `OPENAI_API_KEY` v√°ltoz√≥t

### Hiba: "chromadb nincs telep√≠tve"

```bash
pip install chromadb
```

### Hiba: Dokumentumok nem t√∂lt≈ëdnek be

- Ellen≈ërizd a f√°jl form√°tumot (PDF, TXT, DOCX)
- N√©zd meg a konzol √ºzeneteket hib√°k√©rt

## Tov√°bbi Inform√°ci√≥k

L√°sd a `README.md` f√°jlt r√©szletesebb dokument√°ci√≥√©rt.

