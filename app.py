"""
Streamlit fÅ‘alkalmazÃ¡s
RAG alapÃº AI asszisztens webes felÃ¼lete
"""

import streamlit as st
import os
import sys
import logging
from pathlib import Path
import tempfile
import uuid
from typing import List, Dict, Any, Optional
import pandas as pd

# Projekt mappa hozzÃ¡adÃ¡sa a PYTHONPATH-hoz
project_dir = Path(__file__).parent.absolute()
if str(project_dir) not in sys.path:
    sys.path.insert(0, str(project_dir))

# Logging beÃ¡llÃ­tÃ¡sa
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# RAG rendszer import
from src.rag_system import RAGSystem
from src.utils.session_manager import SessionManager
from src.monitoring.analytics import Analytics
from src.monitoring.metrics import MetricsCollector

# -----------------------------
# UI helper functions
# -----------------------------
def _get_doc_count() -> int:
    try:
        if st.session_state.rag_system is None:
            logger.warning("_get_doc_count: rag_system is None")
            return 0
        stats = st.session_state.rag_system.get_stats()
        doc_count = int(stats.get("vector_db", {}).get("document_count", 0) or 0)
        logger.info(f"_get_doc_count: {doc_count}")
        return doc_count
    except Exception as e:
        logger.error(f"_get_doc_count exception: {e}", exc_info=True)
        return 0


def _new_chat_session():
    """Create a new conversation (keeps vector DB, clears chat history)."""
    st.session_state.current_session_id = st.session_state.session_manager.create_session()
    st.session_state.messages = []


def _format_source(doc: Dict[str, Any], idx: int) -> str:
    md = doc.get("metadata", {}) or {}
    file_name = md.get("file_name") or md.get("source") or "Ismeretlen fÃ¡jl"
    page_number = md.get("page_number")
    chunk_index = md.get("chunk_index")

    parts = [f"**[{idx}]** `{file_name}`"]
    
    # OldalszÃ¡m hozzÃ¡adÃ¡sa (prioritÃ¡s!)
    if page_number is not None:
        parts.append(f"ğŸ“„ **Oldal {page_number}**")
    
    if chunk_index is not None:
        parts.append(f"(chunk: {chunk_index})")
    if doc.get("similarity") is not None:
        try:
            parts.append(f"sim: {float(doc.get('similarity')):.2f}")
        except Exception:
            pass
    if doc.get("rerank_score") is not None:
        try:
            parts.append(f"rerank: {float(doc.get('rerank_score')):.2f}")
        except Exception:
            pass

    return " ".join(parts)


def _handle_feedback(message_id: str, rating: str, query: str = None, response: str = None):
    """Handle user feedback submission"""
    try:
        if st.session_state.rag_system and st.session_state.rag_system.metrics_collector:
            st.session_state.rag_system.metrics_collector.record_user_feedback(
                message_id=message_id,
                rating=rating,
                query=query,
                response=response
            )
            return True
    except Exception as e:
        logger.error(f"Feedback rÃ¶gzÃ­tÃ©si hiba: {e}")
        return False
    return False


def _render_message(message: Dict[str, Any], show_sources: bool, show_feedback: bool = True):
    role = message.get("role", "assistant")
    content = message.get("content", "")
    context = message.get("context")
    message_id = message.get("message_id", str(uuid.uuid4()))

    with st.chat_message(role):
        st.markdown(content)

        if show_sources and role == "assistant" and context:
            with st.expander("ForrÃ¡sok / Kontextus", expanded=False):
                for i, doc in enumerate(context, 1):
                    st.markdown(_format_source(doc, i))
                    text = (doc.get("text") or "").strip()
                    if text:
                        st.caption(text[:800] + ("â€¦" if len(text) > 800 else ""))

        # Feedback gombok asszisztens vÃ¡laszokhoz
        if show_feedback and role == "assistant" and st.session_state.rag_system:
            feedback_key = f"feedback_{message_id}"

            # Ha mÃ©g nincs feedback adva
            if feedback_key not in st.session_state:
                st.caption("Hasznos volt ez a vÃ¡lasz?")
                col1, col2, col3 = st.columns([1, 1, 8])

                with col1:
                    if st.button("ğŸ‘", key=f"pos_{message_id}", help="Hasznos"):
                        if _handle_feedback(message_id, "positive", response=content):
                            st.session_state[feedback_key] = "positive"
                            st.rerun()

                with col2:
                    if st.button("ğŸ‘", key=f"neg_{message_id}", help="Nem hasznos"):
                        if _handle_feedback(message_id, "negative", response=content):
                            st.session_state[feedback_key] = "negative"
                            st.rerun()
            else:
                # Feedback mÃ¡r meg lett adva
                rating = st.session_state[feedback_key]
                icon = "ğŸ‘" if rating == "positive" else "ğŸ‘"
                st.caption(f"{icon} KÃ¶szÃ¶njÃ¼k a visszajelzÃ©st!")

# Oldal konfigurÃ¡ciÃ³
st.set_page_config(
    page_title="RAG AI Asszisztens",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Session state inicializÃ¡lÃ¡sa - EAGER LOADING!
# BetÃ¶ltjÃ¼k a RAG rendszert az oldal betÃ¶ltÃ©sekor, hogy lÃ¡ssa a meglÃ©vÅ‘ dokumentumokat
if 'rag_system' not in st.session_state:
    try:
        st.session_state.rag_system = RAGSystem()
        logger.info("RAG rendszer inicializÃ¡lva (eager loading)")
    except Exception as e:
        st.error(f"RAG rendszer inicializÃ¡lÃ¡si hiba: {e}")
        logger.error(f"RAG init hiba: {e}")
        st.session_state.rag_system = None

if 'session_manager' not in st.session_state:
    st.session_state.session_manager = SessionManager()

if 'current_session_id' not in st.session_state:
    st.session_state.current_session_id = st.session_state.session_manager.create_session()

if 'messages' not in st.session_state:
    st.session_state.messages = []

# FÅ‘oldal
def main_page():
    """FÅ‘oldal - Chat Ã©s dokumentum feltÃ¶ltÃ©s"""
    st.title("ğŸ¤– RAG AlapÃº AI Asszisztens")
    st.markdown("---")
    
    # Sidebar - Dokumentum feltÃ¶ltÃ©s
    with st.sidebar:
        st.header("ğŸ“„ Dokumentum FeltÃ¶ltÃ©s")

        st.subheader("ğŸ’¬ Chat vezÃ©rlÃ©s")
        col_a, col_b = st.columns(2)
        with col_a:
            if st.button("Ãšj chat", use_container_width=True):
                _new_chat_session()
                st.rerun()
        with col_b:
            if st.button("Chat tÃ¶rlÃ©se", use_container_width=True):
                st.session_state.messages = []
                st.rerun()

        show_sources = st.toggle("ForrÃ¡sok megjelenÃ­tÃ©se", value=True)
        
        uploaded_files = st.file_uploader(
            "VÃ¡lassz dokumentumokat",
            type=['pdf', 'txt', 'docx'],
            accept_multiple_files=True
        )
        
        if st.button("Dokumentumok HozzÃ¡adÃ¡sa", type="primary"):
            if not uploaded_files:
                st.warning("ElÅ‘bb vÃ¡lassz ki legalÃ¡bb 1 fÃ¡jlt.")
            elif st.session_state.rag_system is None:
                st.error("RAG rendszer nem inicializÃ¡lÃ³dott. FrissÃ­tsd az oldalt (F5).")
            else:
                with st.spinner("Dokumentumok feldolgozÃ¡sa..."):
                    # FÃ¡jlok mentÃ©se ideiglenes kÃ¶nyvtÃ¡rba
                    temp_dir = Path(tempfile.mkdtemp())
                    file_paths = []
                    
                    for uploaded_file in uploaded_files:
                        file_path = temp_dir / uploaded_file.name
                        with open(file_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        file_paths.append(str(file_path))
                    
                    # Dokumentumok hozzÃ¡adÃ¡sa a RAG rendszerhez
                    try:
                        st.session_state.rag_system.add_documents(file_paths)
                        st.success(f"{len(file_paths)} dokumentum sikeresen hozzÃ¡adva!")
                    except Exception as e:
                        st.error(f"Hiba a dokumentumok hozzÃ¡adÃ¡sÃ¡nÃ¡l: {e}")
                        logger.error(f"Dokumentum hozzÃ¡adÃ¡s hiba: {e}")
        
        st.markdown("---")
        st.header("â„¹ï¸ InformÃ¡ciÃ³k")
        
        # Rendszer statisztikÃ¡k
        doc_count = _get_doc_count()
        st.metric("Dokumentumok (vector DB)", doc_count)
        st.caption(f"Session: `{st.session_state.current_session_id}`")
    
    # Chat felÃ¼let
    st.header("ğŸ’¬ Chat")
    
    # Ãœzenetek megjelenÃ­tÃ©se
    for message in st.session_state.messages:
        _render_message(message, show_sources=show_sources)
    
    # Chat input ellenÅ‘rzÃ©sek
    if st.session_state.rag_system is None:
        st.error("âš ï¸ RAG rendszer nem inicializÃ¡lÃ³dott. FrissÃ­tsd az oldalt (F5).")
        return

    doc_count = _get_doc_count()
    if doc_count <= 0:
        st.info("ğŸ“„ Nincs dokumentum a vector adatbÃ¡zisban. TÃ¶lts fel PDF/TXT/DOCX fÃ¡jlokat a bal oldali feltÃ¶ltÅ‘vel!")
        return

    if prompt := st.chat_input("KÃ©rdezz valamit a dokumentumokrÃ³l..."):
        # FelhasznÃ¡lÃ³ Ã¼zenet hozzÃ¡adÃ¡sa
        user_msg_id = str(uuid.uuid4())
        st.session_state.messages.append({
            "role": "user",
            "content": prompt,
            "message_id": user_msg_id
        })
        st.session_state.session_manager.add_message(
            st.session_state.current_session_id,
            "user",
            prompt
        )

        with st.chat_message("user"):
            st.markdown(prompt)

        # Asszisztens vÃ¡lasz generÃ¡lÃ¡sa
        assistant_msg_id = str(uuid.uuid4())
        with st.chat_message("assistant"):
            try:
                # Streaming vÃ¡lasz
                response = st.session_state.rag_system.query(prompt, stream=True)

                message_placeholder = st.empty()
                full_response = ""
                context_docs = response.get("context") or []

                # buffereljÃ¼k, ha karakterenkÃ©nt jÃ¶n (ne frissÃ­tsÃ¼nk tÃºl gyakran)
                buffer = ""
                for chunk in response["generator"]:
                    buffer += chunk
                    if len(buffer) >= 32:
                        full_response += buffer
                        buffer = ""
                        message_placeholder.markdown(full_response + "â–Œ")

                if buffer:
                    full_response += buffer
                    message_placeholder.markdown(full_response + "â–Œ")

                message_placeholder.markdown(full_response)

                # LLM metrikÃ¡k rÃ¶gzÃ­tÃ©se streaming utÃ¡n
                try:
                    estimated_tokens = len(full_response.split()) * 1.3
                    prompt_tokens = int(estimated_tokens * 0.7)
                    completion_tokens = int(estimated_tokens * 0.3)
                    model_name = st.session_state.rag_system.llm_generator.model_name

                    cost = st.session_state.rag_system.metrics_collector.calculate_cost(
                        model_name, prompt_tokens, completion_tokens
                    )

                    st.session_state.rag_system.metrics_collector.record_llm_call(
                        prompt_tokens=prompt_tokens,
                        completion_tokens=completion_tokens,
                        model=model_name,
                        cost=cost
                    )
                except Exception as metric_error:
                    logger.warning(f"Metrika rÃ¶gzÃ­tÃ©s hiba: {metric_error}")

                if show_sources and context_docs:
                    with st.expander("ForrÃ¡sok / Kontextus", expanded=False):
                        for i, doc in enumerate(context_docs, 1):
                            st.markdown(_format_source(doc, i))
                            text = (doc.get("text") or "").strip()
                            if text:
                                st.caption(text[:800] + ("â€¦" if len(text) > 800 else ""))

                # Feedback gombok
                st.caption("Hasznos volt ez a vÃ¡lasz?")
                col1, col2, col3 = st.columns([1, 1, 8])

                feedback_key = f"feedback_{assistant_msg_id}"
                with col1:
                    if st.button("ğŸ‘", key=f"pos_{assistant_msg_id}", help="Hasznos"):
                        if _handle_feedback(assistant_msg_id, "positive", query=prompt, response=full_response):
                            st.session_state[feedback_key] = "positive"

                with col2:
                    if st.button("ğŸ‘", key=f"neg_{assistant_msg_id}", help="Nem hasznos"):
                        if _handle_feedback(assistant_msg_id, "negative", query=prompt, response=full_response):
                            st.session_state[feedback_key] = "negative"

                # VÃ¡lasz mentÃ©se
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_response,
                    "context": context_docs,
                    "message_id": assistant_msg_id
                })
                st.session_state.session_manager.add_message(
                    st.session_state.current_session_id,
                    "assistant",
                    full_response,
                    metadata={"context": context_docs},
                )
            
            except Exception as e:
                error_message = f"Hiba tÃ¶rtÃ©nt: {str(e)}"
                st.error(error_message)
                logger.error(f"Chat hiba: {e}")
                st.session_state.messages.append({"role": "assistant", "content": error_message})
                st.session_state.session_manager.add_message(
                    st.session_state.current_session_id,
                    "assistant",
                    error_message,
                    metadata={"error": True},
                )


# Monitoring oldal
def monitoring_page():
    """Monitoring Ã©s analitika oldal"""
    st.title("ğŸ“Š Monitoring Ã©s Analitika")
    st.markdown("---")
    
    try:
        metrics_collector = st.session_state.rag_system.metrics_collector
        analytics = Analytics(metrics_collector)
        
        # StatisztikÃ¡k
        stats = metrics_collector.get_statistics(days=30)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("LLM HÃ­vÃ¡sok", stats.get('total_llm_calls', 0))
        with col2:
            st.metric("Ã–sszes Tokenek", f"{stats.get('total_tokens', 0):,}")
        with col3:
            st.metric("Ã–sszes KÃ¶ltsÃ©g", f"${stats.get('total_cost_usd', 0):.4f}")
        with col4:
            avg_time = stats.get('avg_total_time_sec', 0)
            st.metric("Ãtlagos VÃ¡laszidÅ‘", f"{avg_time:.2f}s" if avg_time else "N/A")
        
        st.markdown("---")
        
        # Napi hasznÃ¡lat grafikon
        st.subheader("Napi HasznÃ¡lat")
        daily_usage = analytics.get_daily_usage(days=30)
        
        if not daily_usage.empty:
            import plotly.express as px
            
            fig = px.line(
                daily_usage,
                x='date',
                y='total_tokens',
                title='Napi Token HasznÃ¡lat',
                labels={'date': 'DÃ¡tum', 'total_tokens': 'Tokenek'}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Latency trendek
        st.subheader("Latency Trendek")
        latency_trends = analytics.get_latency_trends(days=7)
        
        if not latency_trends.empty:
            import plotly.express as px
            import pandas as pd  # Local import for nested scope
            
            # Adatok tisztÃ­tÃ¡sa Ã©s tÃ­pus konverziÃ³
            try:
                # Numerikus oszlopok konverziÃ³ja
                latency_trends['first_token_time'] = pd.to_numeric(latency_trends['first_token_time'], errors='coerce')
                latency_trends['total_time'] = pd.to_numeric(latency_trends['total_time'], errors='coerce')
                
                # NaN Ã©rtÃ©kek eltÃ¡volÃ­tÃ¡sa
                latency_trends = latency_trends.dropna(subset=['first_token_time', 'total_time'])
                
                if not latency_trends.empty:
                    fig = px.line(
                        latency_trends,
                        x='date',
                        y=['first_token_time', 'total_time'],
                        title='Latency Trendek',
                        labels={'date': 'DÃ¡tum', 'value': 'IdÅ‘ (mÃ¡sodperc)'}
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("Nincs elÃ©g adat a latency trendek megjelenÃ­tÃ©sÃ©hez.")
            except Exception as e:
                st.warning(f"Latency grafikon hiba: {e}")
                logger.warning(f"Latency plot error: {e}")
        
        # Modell hasznÃ¡lat
        st.subheader("Modell HasznÃ¡lat")
        model_usage = analytics.get_model_usage()

        if model_usage:
            import pandas as pd
            df = pd.DataFrame(model_usage).T.reset_index()
            df.columns = ['Modell', 'Tokenek', 'KÃ¶ltsÃ©g', 'HÃ­vÃ¡sok']
            st.dataframe(df, use_container_width=True)

        st.markdown("---")

        # FelhasznÃ¡lÃ³i Feedback
        st.subheader("ğŸ“ FelhasznÃ¡lÃ³i Feedback")
        feedback_stats = metrics_collector.get_feedback_statistics(days=30)

        if feedback_stats.get('total_feedbacks', 0) > 0:
            # Feedback metrikÃ¡k
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("Ã–sszes Feedback", feedback_stats.get('total_feedbacks', 0))
            with col2:
                st.metric("ğŸ‘ PozitÃ­v", feedback_stats.get('positive', 0))
            with col3:
                st.metric("ğŸ‘ NegatÃ­v", feedback_stats.get('negative', 0))
            with col4:
                satisfaction = feedback_stats.get('satisfaction_score', 0)
                st.metric("ElÃ©gedettsÃ©g", f"{satisfaction:.1f}%")

            # Feedback eloszlÃ¡s (Pie chart)
            feedback_dist = analytics.get_feedback_distribution()
            if any(feedback_dist.values()):
                import plotly.express as px

                fig = px.pie(
                    values=list(feedback_dist.values()),
                    names=list(feedback_dist.keys()),
                    title='Feedback EloszlÃ¡s',
                    color_discrete_map={'positive': '#00CC96', 'negative': '#EF553B', 'neutral': '#636EFA'}
                )
                st.plotly_chart(fig, use_container_width=True)

            # LegutÃ³bbi kommentek
            recent_comments = feedback_stats.get('recent_comments', [])
            if recent_comments:
                st.subheader("LegutÃ³bbi VisszajelzÃ©sek")
                for comment_data in recent_comments:
                    rating = comment_data.get('rating', 'neutral')
                    icon = "ğŸ‘" if rating == 'positive' else "ğŸ‘" if rating == 'negative' else "â–"
                    query = comment_data.get('query', 'N/A')
                    comment = comment_data.get('comment', '')
                    timestamp = comment_data.get('timestamp', '')

                    st.markdown(f"**{icon} {rating.upper()}** - {timestamp[:10]}")
                    st.caption(f"KÃ©rdÃ©s: {query}")
                    if comment:
                        st.info(comment)
        else:
            st.info("MÃ©g nincs felhasznÃ¡lÃ³i feedback. A chat-ben adj visszajelzÃ©st a vÃ¡laszokhoz!")

    except Exception as e:
        st.error(f"Hiba a monitoring betÃ¶ltÃ©sÃ©nÃ©l: {e}")
        logger.error(f"Monitoring hiba: {e}")


# Evaluation oldal
def evaluation_page():
    """Evaluation oldal - RAG, Prompt, App szintÅ± Ã©rtÃ©kelÃ©s az UI-bÃ³l"""
    st.title("ğŸ§ª Evaluation")
    st.markdown("---")

    if st.session_state.rag_system is None:
        st.error("RAG rendszer nem inicializÃ¡lÃ³dott. FrissÃ­tsd az oldalt (F5).")
        return

    rag_system = st.session_state.rag_system
    doc_count = _get_doc_count()

    from src.evaluation.rag_eval import RAGEvaluator
    from src.evaluation.prompt_eval import PromptEvaluator
    from src.evaluation.app_eval import AppEvaluator
    from src.evaluation.test_cases import RAG_TEST_CASES, PROMPT_TEST_CASES, APP_TEST_CASES

    tab1, tab2, tab3 = st.tabs(["ğŸ“Š RAG SzintÅ±", "ğŸ’¬ Prompt SzintÅ±", "ğŸš€ AlkalmazÃ¡s SzintÅ±"])

    # â”€â”€ TAB 1: RAG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tab1:
        st.subheader("ğŸ“Š RAG SzintÅ± Ã‰rtÃ©kelÃ©s")

        # -- Retrieval --
        st.markdown("### Retrieval MinÅ‘sÃ©g (Precision / Recall / MRR)")
        if doc_count <= 0:
            st.warning("Nincs dokumentum a vector DB-ben. TÃ¶lts fel dokumentumokat a FÅ‘oldalon a retrieval Ã©rtÃ©kelÃ©s elÅ‘tt!")

        if st.button("Retrieval Ã‰rtÃ©kelÃ©s FuttatÃ¡sa", disabled=(doc_count <= 0), key="btn_ret"):
            with st.spinner("Retrieval Ã©rtÃ©kelÃ©s folyamatban..."):
                ev = RAGEvaluator(
                    vector_store=rag_system.vector_store,
                    retrieval_engine=rag_system.retrieval_engine,
                    embedding_model=rag_system.embedding_model,
                    chunking_strategy=rag_system.chunking,
                )
                res = ev.evaluate_retrieval_by_keywords(RAG_TEST_CASES['retrieval_tests'])
                st.session_state.eval_retrieval = res
                ev.save_results(res, str(Path("evaluations/rag_retrieval_results.json")))

        res = st.session_state.get('eval_retrieval')
        if res:
            km = res.get('keyword_metrics', {})
            br = res.get('basic_retrieval', {})
            st.markdown(f"**Tesla-specifikus tesztek** ({km.get('num_queries', 0)} query, kulcsszÃ³ alapÃº)")
            c1, c2, c3 = st.columns(3)
            c1.metric("Precision", f"{km.get('precision', 0):.3f}")
            c2.metric("Recall", f"{km.get('recall', 0):.3f}")
            c3.metric("MRR", f"{km.get('mrr', 0):.3f}")
            if br.get('num_queries', 0) > 0:
                st.markdown(f"**ÃltalÃ¡nos retrieval teszt** ({br['num_queries']} query)")
                st.metric("SikeressÃ©gi arÃ¡ny", f"{br.get('success_rate', 0):.1%}")
            with st.expander("RÃ©szletes eredmÃ©nyek", expanded=False):
                kw_details = [d for d in res.get('details', []) if d.get('type') == 'keyword']
                if kw_details:
                    df = pd.DataFrame([{
                        'Query': d['query'][:60],
                        'Precision': d.get('precision', 0),
                        'Recall': d.get('recall', 0),
                        'MRR': d.get('mrr', 0),
                        'TalÃ¡lt kulcsszavak': ', '.join(d.get('keywords_found', [])),
                    } for d in kw_details])
                    st.dataframe(df, use_container_width=True)

        st.markdown("---")

        # -- Embedding --
        st.markdown("### Embedding Modell TeljesÃ­tmÃ©ny")
        if st.button("Embedding Ã‰rtÃ©kelÃ©s FuttatÃ¡sa", key="btn_emb"):
            with st.spinner("Embedding Ã©rtÃ©kelÃ©s folyamatban..."):
                ev = RAGEvaluator(
                    vector_store=rag_system.vector_store,
                    retrieval_engine=rag_system.retrieval_engine,
                    embedding_model=rag_system.embedding_model,
                )
                res = ev.evaluate_embedding_quality(RAG_TEST_CASES['embedding_tests'])
                st.session_state.eval_embedding = res
                ev.save_results(res, str(Path("evaluations/rag_embedding_results.json")))

        res = st.session_state.get('eval_embedding')
        if res:
            c1, c2, c3 = st.columns(3)
            c1.metric("KorrelÃ¡ciÃ³", f"{res.get('correlation', 0):.3f}")
            c2.metric("Ãtlag prediktÃ¡lt sim.", f"{res.get('mean_predicted_sim', 0):.3f}")
            c3.metric("Ãtlag valÃ³s sim.", f"{res.get('mean_true_sim', 0):.3f}")
            st.caption(f"Teszt pÃ¡rok szÃ¡ma: {res.get('num_pairs', 0)}")

        st.markdown("---")

        # -- Chunking --
        st.markdown("### Chunking StratÃ©gia HatÃ©konysÃ¡g")
        if st.button("Chunking Ã‰rtÃ©kelÃ©s FuttatÃ¡sa", key="btn_chk"):
            with st.spinner("Chunking Ã©rtÃ©kelÃ©s folyamatban..."):
                ev = RAGEvaluator(
                    vector_store=rag_system.vector_store,
                    retrieval_engine=rag_system.retrieval_engine,
                    embedding_model=rag_system.embedding_model,
                    chunking_strategy=rag_system.chunking,
                )
                res = ev.evaluate_chunking_tests(RAG_TEST_CASES['chunking_tests'])
                st.session_state.eval_chunking = res
                ev.save_results(res, str(Path("evaluations/rag_chunking_results.json")))

        res = st.session_state.get('eval_chunking')
        if res:
            c1, c2, c3 = st.columns(3)
            c1.metric("Chunk szÃ¡m pontossÃ¡g", f"{res.get('chunk_count_accuracy', 0):.1%}")
            c2.metric("MÃ©ret Ã©rvÃ©nyessÃ©g", f"{res.get('size_validity_rate', 0):.1%}")
            c3.metric("Tesztek szÃ¡ma", res.get('total_tests', 0))
            with st.expander("RÃ©szletes eredmÃ©nyek", expanded=False):
                for tr in res.get('test_results', []):
                    s = tr.get('statistics', {})
                    match = "âœ…" if tr.get('chunk_count_match') else "âŒ"
                    st.markdown(
                        f"{match} ElvÃ¡rt: **{tr['expected_chunks']}** chunk, "
                        f"Kapott: **{tr['actual_chunks']}** chunk â€” "
                        f"Ãtlag mÃ©ret: {s.get('avg_chunk_size', 0):.0f}, "
                        f"Min: {s.get('min_chunk_size', 0)}, Max: {s.get('max_chunk_size', 0)}"
                    )

    # â”€â”€ TAB 2: Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tab2:
        st.subheader("ğŸ’¬ Prompt SzintÅ± Ã‰rtÃ©kelÃ©s")
        st.caption(f"Tesztek szÃ¡ma: {len(PROMPT_TEST_CASES)} | Context relevance, hallucinÃ¡ciÃ³ detektÃ¡lÃ¡s, LLM-as-Judge")

        col1, col2 = st.columns([3, 1])
        with col1:
            run_eval = st.button("Prompt Ã‰rtÃ©kelÃ©s FuttatÃ¡sa", key="btn_prompt")
        with col2:
            if st.button("ğŸ—‘ï¸ Cache TÃ¶rlÃ©se", key="btn_clear_prompt"):
                if 'eval_prompt' in st.session_state:
                    del st.session_state.eval_prompt
                st.success("Cache tÃ¶rÃ¶lve!")
                st.rerun()
        
        if run_eval:
            import time
            start_time = time.time()
            with st.spinner(f"Prompt Ã©rtÃ©kelÃ©s futtatÃ¡sa ({len(PROMPT_TEST_CASES)} teszt, ez pÃ¡r percig tarthat)..."):
                ev = PromptEvaluator(llm_generator=rag_system.llm_generator)
                res = ev.run_evaluation(PROMPT_TEST_CASES)
                res['_run_timestamp'] = time.time()  # IdÅ‘bÃ©lyeg hozzÃ¡adÃ¡sa
                res['_run_duration'] = time.time() - start_time
                st.session_state.eval_prompt = res
                ev.save_results(res, str(Path("evaluations/prompt_evaluation_results.json")))
            st.success(f"âœ… Ã‰rtÃ©kelÃ©s befejezve {res['_run_duration']:.1f} mÃ¡sodperc alatt!")

        res = st.session_state.get('eval_prompt')
        if res:
            summary = res.get('summary', {})
            
            # IdÅ‘bÃ©lyeg megjelenÃ­tÃ©se (ha van)
            if '_run_timestamp' in res:
                import datetime
                run_time = datetime.datetime.fromtimestamp(res['_run_timestamp'])
                st.caption(f"â±ï¸ UtolsÃ³ futtatÃ¡s: {run_time.strftime('%Y-%m-%d %H:%M:%S')} ({res.get('_run_duration', 0):.1f}s)")
            
            c1, c2, c3 = st.columns(3)
            c1.metric("Tesztek szÃ¡ma", summary.get('num_tests', 0))
            c2.metric("Ãtlag Context Relevance", f"{summary.get('avg_context_relevance', 0):.3f}")
            c3.metric("Ãtlag HallucinÃ¡ciÃ³ Score", f"{summary.get('avg_hallucination_score', 0):.3f}")
            with st.expander("TesztenkÃ©nti eredmÃ©nyek", expanded=False):
                test_results = res.get('results', [])
                if test_results:
                    df = pd.DataFrame([{
                        'Query': r['query'][:50],
                        'Context Rel.': round(r.get('context_relevance', 0), 3),
                        'HallucinÃ¡ciÃ³': round(r.get('hallucination_score', 0), 3),
                        'VÃ¡lasz (rÃ©szlet)': (r.get('answer', '') or '')[:80],
                    } for r in test_results])
                    st.dataframe(df, use_container_width=True)

    # â”€â”€ TAB 3: AlkalmazÃ¡s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tab3:
        st.subheader("ğŸš€ AlkalmazÃ¡s SzintÅ± Ã‰rtÃ©kelÃ©s")

        # -- Latency --
        st.markdown("### Latency Teszt")
        if doc_count <= 0:
            st.warning("Nincs dokumentum a vector DB-ben. TÃ¶lts fel dokumentumokat a latency teszt elÅ‘tt!")
        lat_queries = APP_TEST_CASES.get('latency_tests', {}).get('queries', [])
        num_runs = APP_TEST_CASES.get('latency_tests', {}).get('num_runs', 3)

        if st.button("Latency Teszt FuttatÃ¡sa", disabled=(doc_count <= 0), key="btn_lat"):
            import time
            start_time = time.time()
            try:
                with st.spinner(f"Latency teszt ({len(lat_queries)} query x {num_runs} futtatÃ¡s)..."):
                    ev = AppEvaluator(rag_system=rag_system)
                    res = ev.evaluate_latency(lat_queries, num_runs=num_runs)
                    res['_run_timestamp'] = time.time()
                    res['_run_duration'] = time.time() - start_time
                    st.session_state.eval_latency = res
                    ev.save_results({'latency': res}, str(Path("evaluations/app_latency_results.json")))
                st.success(f"âœ… Latency teszt befejezve {res['_run_duration']:.1f} mÃ¡sodperc alatt!")
            except Exception as e:
                st.error(f"âŒ Latency teszt hiba: {e}")
                logger.error(f"Latency teszt hiba: {e}", exc_info=True)

        res = st.session_state.get('eval_latency')
        if res:
            # IdÅ‘bÃ©lyeg megjelenÃ­tÃ©se (ha van)
            if '_run_timestamp' in res:
                import datetime
                run_time = datetime.datetime.fromtimestamp(res['_run_timestamp'])
                st.caption(f"â±ï¸ UtolsÃ³ futtatÃ¡s: {run_time.strftime('%Y-%m-%d %H:%M:%S')} ({res.get('_run_duration', 0):.1f}s)")
            
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("Ãtlag First Token", f"{res.get('avg_first_token_time', 0):.2f}s")
            c2.metric("Ãtlag Total Time", f"{res.get('avg_total_time', 0):.2f}s")
            c3.metric("P95 First Token", f"{res.get('p95_first_token_time', 0):.2f}s")
            c4.metric("P95 Total Time", f"{res.get('p95_total_time', 0):.2f}s")
            st.caption(f"{res.get('num_queries', 0)} query x {res.get('num_runs_per_query', 0)} futtatÃ¡s")

        st.markdown("---")

        # -- User Journey --
        st.markdown("### User Journey Teszt")
        journeys = APP_TEST_CASES.get('user_journeys', [])
        if doc_count <= 0:
            st.warning("Nincs dokumentum a vector DB-ben. TÃ¶lts fel dokumentumokat a user journey teszt elÅ‘tt!")

        if st.button("User Journey Teszt FuttatÃ¡sa", disabled=(doc_count <= 0), key="btn_uj"):
            import time
            start_time = time.time()
            try:
                with st.spinner(f"User journey teszt ({len(journeys)} journey)..."):
                    ev = AppEvaluator(rag_system=rag_system)
                    res = ev.run_full_evaluation(APP_TEST_CASES)
                    res['_run_timestamp'] = time.time()
                    res['_run_duration'] = time.time() - start_time
                    st.session_state.eval_journey = res
                    ev.save_results(res, str(Path("evaluations/app_evaluation_results.json")))
                st.success(f"âœ… User journey teszt befejezve {res['_run_duration']:.1f} mÃ¡sodperc alatt!")
            except Exception as e:
                st.error(f"âŒ User journey teszt hiba: {e}")
                logger.error(f"User journey teszt hiba: {e}", exc_info=True)

        res = st.session_state.get('eval_journey')
        if res and 'user_journeys' in res:
            # IdÅ‘bÃ©lyeg megjelenÃ­tÃ©se (ha van)
            if '_run_timestamp' in res:
                import datetime
                run_time = datetime.datetime.fromtimestamp(res['_run_timestamp'])
                st.caption(f"â±ï¸ UtolsÃ³ futtatÃ¡s: {run_time.strftime('%Y-%m-%d %H:%M:%S')} ({res.get('_run_duration', 0):.1f}s)")
            
            jrs = res['user_journeys']
            success_count = sum(1 for jr in jrs if jr.get('success_rate', 0) >= 0.5)
            st.metric("Journey sikeressÃ©g", f"{success_count}/{len(jrs)}")
            with st.expander("RÃ©szletes journey eredmÃ©nyek", expanded=False):
                for i, jr in enumerate(jrs):
                    name = journeys[i]['name'] if i < len(journeys) else f"Journey {i+1}"
                    rate = jr.get('success_rate', 0)
                    t = jr.get('total_time', 0)
                    icon = "âœ…" if rate >= 0.5 else "âŒ"
                    st.markdown(f"{icon} **{name}** â€” SikeressÃ©g: {rate:.0%}, IdÅ‘: {t:.1f}s")


# FÅ‘ navigÃ¡ciÃ³
def main():
    """FÅ‘ fÃ¼ggvÃ©ny"""
    pages = {
        "ğŸ  FÅ‘oldal": main_page,
        "ğŸ“Š Monitoring": monitoring_page,
        "ğŸ§ª Evaluation": evaluation_page
    }
    
    # Sidebar navigÃ¡ciÃ³
    st.sidebar.title("NavigÃ¡ciÃ³")
    selected_page = st.sidebar.radio("VÃ¡lassz oldalt", list(pages.keys()))
    
    # KivÃ¡lasztott oldal megjelenÃ­tÃ©se
    pages[selected_page]()


if __name__ == "__main__":
    main()

